{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbJrNUkpmbmYG1y2BBZQRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rapidsnopp/MNIST-CNN/blob/main/Bai_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjEHR-SySbWD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weight(shape, init = 'default', fan_in = None, fan_out = None):\n",
        "  if init =='xavier':\n",
        "    limit = np.sqrt(6/(fan_in + fan_out))\n",
        "    return np.random.uniform(-limit, limit, shape)\n",
        "  elif init == 'he':\n",
        "    std = np.sqrt(2/fan_in)\n",
        "    return np.random.randn(*shape) * std\n",
        "  else:\n",
        "    return np.random.randn(*shape) * 0.01"
      ],
      "metadata": {
        "id": "SZR6fpL3S3id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(x, padding: int | tuple | list, padding_type='zero'):\n",
        "    assert padding_type in ['zero', 'reflect', 'edge', 'symmetric']\n",
        "    if isinstance(padding, int):\n",
        "        padding = (padding, padding)\n",
        "    if padding_type == 'zero':\n",
        "        return np.pad(x, ((0, 0), (0, 0), (padding[0], padding[0]), (padding[1], padding[1])),\n",
        "                      'constant', constant_values=0)\n",
        "    else:\n",
        "        return np.pad(x, ((0, 0), (0, 0), (padding[0], padding[0]), (padding[1], padding[1])), padding_type)\n",
        "\n",
        "def dilation(x, dilation: int | tuple | list):\n",
        "    if isinstance(dilation, int):\n",
        "        dilation = (dilation, dilation)\n",
        "    if dilation == 0:\n",
        "        return x\n",
        "    size = x.shape\n",
        "    h_out = size[2] + (size[2]-1) * dilation[0]\n",
        "    w_out = size[3] + (size[3]-1) * dilation[1]\n",
        "    out = np.zeros((size[0], size[1], h_out, w_out))\n",
        "    pad = dilation[0] + 1\n",
        "    for i in range(size[2]):\n",
        "        for j in range(size[3]):\n",
        "            out[:, :, i*pad, j*pad] = x[:, :, i, j]\n",
        "    return out"
      ],
      "metadata": {
        "id": "P6gz40ygTlA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2d:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size: int | list | tuple, stride=1, padding=0, padding_type='edge', is_bias=True):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        assert isinstance(kernel_size, (int, list, tuple))\n",
        "        if isinstance(kernel_size, (tuple, list)):\n",
        "            assert len(kernel_size) == 2\n",
        "            self.kernel_size = kernel_size\n",
        "        else:\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.weights = np.random.randn(out_channels, in_channels, self.kernel_size[0], self.kernel_size[1])\n",
        "        self.bias = np.random.randn(out_channels) if is_bias else None\n",
        "        self.padding_type = padding_type\n",
        "        self.training = True\n",
        "        self.input = None\n",
        "        self.w_grad = None\n",
        "        self.b_grad = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 3:\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "        x = padding(x, self.padding, self.padding_type)\n",
        "        if self.training:\n",
        "            self.input = x\n",
        "        batch_size, in_channels, height, width = x.shape\n",
        "        assert in_channels == self.in_channels\n",
        "        out = self._calculate_conv2d(x, self.weights, self.bias)\n",
        "        return out\n",
        "\n",
        "    def _calculate_conv2d(self, x, kernel, bias=None):\n",
        "        batch, in_channels, height, width = x.shape\n",
        "        out_channels, _, k_h, k_w = kernel.shape\n",
        "\n",
        "        out_height = (height - k_h) // self.stride + 1\n",
        "        out_width = (width - k_w) // self.stride + 1\n",
        "\n",
        "        size = [batch, out_channels, out_height, out_width]\n",
        "        out = np.zeros(size)\n",
        "\n",
        "        kernel = np.expand_dims(kernel, axis=0)\n",
        "        input_exp = np.expand_dims(x, axis=1)\n",
        "\n",
        "        kernel = np.repeat(kernel, repeats=size[0], axis=0)\n",
        "        input_exp = np.repeat(input_exp, repeats=size[1], axis=1)\n",
        "\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                h = i * self.stride\n",
        "                w = j * self.stride\n",
        "                out[:, :, i, j] = np.sum(input_exp[:, :, :, h:h+k_h, w:w+k_w] * kernel, axis=(-1, -2, -3))\n",
        "        if bias is not None:\n",
        "            bias = bias.reshape(1, self.out_channels, 1, 1)\n",
        "            out += bias\n",
        "        return out\n",
        "\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        assert self.input is not None\n",
        "        x = np.transpose(self.input, (1, 0, 2, 3))\n",
        "        kernel_back_w = np.transpose(grad_output, (1, 0, 2, 3))\n",
        "        kernel_back_w = dilation(kernel_back_w, self.stride-1)\n",
        "        w_grad = self._calculate_conv2d(x, kernel_back_w)\n",
        "        w_grad = np.transpose(w_grad, (1, 0, 2, 3))\n",
        "        b_grad = np.sum(grad_output, axis=(0, 2, 3))\n",
        "        self.w_grad = w_grad\n",
        "        self.b_grad = b_grad\n",
        "        w = np.transpose(self.weights, (1, 0, 2, 3))\n",
        "        dilation_out = dilation(grad_output, self.stride-1)\n",
        "        padding_grad_output = padding(dilation_out, (w.shape[2]-1, w.shape[3]-1))\n",
        "        grad_input = self._calculate_conv2d(padding_grad_output, w[:, :, ::-1, ::-1])\n",
        "        if self.padding > 0:\n",
        "            grad_input = grad_input[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
        "        return grad_input\n",
        "\n",
        "    def update(self, lr):\n",
        "        if self.w_grad is None or self.b_grad is None:\n",
        "            return\n",
        "        self.weights -= lr * self.w_grad\n",
        "        if self.bias is not None:\n",
        "            self.bias -= lr * self.b_grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.w_grad = None\n",
        "        self.b_grad = None\n",
        "\n",
        "    def eval(self):\n",
        "        self.training = False\n",
        "\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "5HeBWQChTm2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2d:\n",
        "    def __init__(self, kernel_size: int | list | tuple, stride=2, padding=0, padding_type='edge'):\n",
        "        if isinstance(kernel_size, (tuple, list)):\n",
        "            assert len(kernel_size) == 2\n",
        "            self.kernel_size = kernel_size\n",
        "        else:\n",
        "            self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.padding_type = padding_type\n",
        "        self.input = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 3:\n",
        "            x = np.expand_dims(x, axis=0)\n",
        "        x = padding(x, self.padding, self.padding_type)\n",
        "        self.input = x\n",
        "        out = self._calculate_maxpool2d(x)\n",
        "        return out\n",
        "\n",
        "    def _calculate_maxpool2d(self, x):\n",
        "        batch, in_channels, height, width = x.shape\n",
        "        out_height = (height - self.kernel_size[0]) // self.stride + 1\n",
        "        out_width = (width - self.kernel_size[1]) // self.stride + 1\n",
        "        size = [batch, in_channels, out_height, out_width]\n",
        "        out = np.zeros(size)\n",
        "        for i in range(out_height):\n",
        "            for j in range(out_width):\n",
        "                h = i * self.stride\n",
        "                w = j * self.stride\n",
        "                out[:, :, i, j] = np.max(x[:, :, h:h+self.kernel_size[0], w:w+self.kernel_size[1]], axis=(-1, -2))\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        assert self.input is not None\n",
        "        x = self.input\n",
        "        grad_input = np.zeros(x.shape)\n",
        "        size = grad_output.shape\n",
        "        for i in range(size[2]):\n",
        "            for j in range(size[3]):\n",
        "                h = i * self.stride\n",
        "                w = j * self.stride\n",
        "                x_slice = x[:, :, h:h+self.kernel_size[0], w:w+self.kernel_size[1]]\n",
        "                max_val = np.max(x_slice, axis=(-1, -2), keepdims=True)\n",
        "                mask = (x_slice == max_val).astype(int)\n",
        "                grad = grad_output[:, :, i, j][:, :, None, None]\n",
        "                grad_input[:, :, h:h+self.kernel_size[0], w:w+self.kernel_size[1]] += mask * grad\n",
        "        if self.padding > 0:\n",
        "            grad_input = grad_input[:, :, self.padding:-self.padding, self.padding:-self.padding]\n",
        "        return grad_input\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "cq3hFu4QucDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        self.w = np.random.randn(in_channels, out_channels) * 0.01\n",
        "        self.b = np.zeros(out_channels)\n",
        "        self.training = True\n",
        "        self.input = None\n",
        "        self.w_grad = None\n",
        "        self.b_grad = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            self.input = x\n",
        "        return np.dot(x, self.w) + self.b\n",
        "\n",
        "    def backward(self, out_grad):\n",
        "        x = self.input\n",
        "        self.w_grad = np.dot(x.T, out_grad)\n",
        "        self.b_grad = np.sum(out_grad, axis=0)\n",
        "        return np.dot(out_grad, self.w.T)\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.w -= lr * self.w_grad\n",
        "        self.b -= lr * self.b_grad\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.w_grad = np.zeros_like(self.w)\n",
        "        self.b_grad = np.zeros_like(self.b)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        self.training = False\n",
        "\n",
        "    def train(self):\n",
        "        self.training = True"
      ],
      "metadata": {
        "id": "oyzqK2L5ucA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid activation\n",
        "class Sigmoid:\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def backward(self, out_grad):\n",
        "        sig = self.forward(self.input)\n",
        "        return out_grad * sig * (1 - sig)\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "# Tanh activattion\n",
        "class Tanh:\n",
        "  def forward(self, x):\n",
        "    self.input = x\n",
        "    return np.tanh(x)\n",
        "\n",
        "  def backward(self, out_grad):\n",
        "    tanh = self.forward(self.input)\n",
        "    return out_grad * (1 - tanh**2)\n",
        "\n",
        "  def update(self, lr):\n",
        "    pass\n",
        "\n",
        "  def zero_grad(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.forward(x)\n",
        "\n",
        "  def eval(self):\n",
        "    pass\n",
        "\n",
        "  def train(self):\n",
        "    pass\n",
        "\n",
        "# ReLU activation\n",
        "class ReLU:\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def backward(self, out_grad):\n",
        "        return out_grad * (self.input > 0)\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "# Leaky ReLU activaation\n",
        "class LeakyReLU:\n",
        "    def __init__(self, alpha=0.1):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        return np.maximum(self.alpha*x, x)\n",
        "\n",
        "    def backward(self, out_grad):\n",
        "        return out_grad * (self.input > 0) + self.alpha * out_grad\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass\n",
        "\n",
        "# Maxout activation\n",
        "class Maxout:\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.input = x\n",
        "    return np.max(x.reshape(x.shape[0], x.shape[1] // 2, 2, x.shape[2], x.shape[3]), axis=2)\n",
        "\n",
        "  def backward(self, out_grad):\n",
        "    return out_grad\n",
        "\n",
        "  def update(self, lr):\n",
        "    pass\n",
        "\n",
        "  def zero_grad(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.forward(x)\n",
        "\n",
        "  def eval(self):\n",
        "    pass\n",
        "\n",
        "  def train(self):\n",
        "    pass\n",
        "\n",
        "\n",
        "# ELU activation\n",
        "class ELU:\n",
        "  def __init__(self, alpha=0.1):\n",
        "    self.alpha = alpha\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.input = x\n",
        "    return np.where(x > 0, x, self.alpha * (np.exp(x) - 1))\n",
        "\n",
        "  def backward(self, out_grad):\n",
        "    return np.where(self.input > 0, out_grad, out_grad * self.alpha * np.exp(self.input))\n",
        "\n",
        "  def update(self, lr):\n",
        "    pass\n",
        "\n",
        "  def zero_grad(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.forward(x)\n",
        "\n",
        "  def eval(self):\n",
        "    pass\n",
        "\n",
        "  def train(self):\n",
        "    pass"
      ],
      "metadata": {
        "id": "JMhyzK-gub-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropyLoss:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Đảm bảo y_pred không có giá trị quá 0\n",
        "        y_pred = np.clip(y_pred, 1e-7, 1)\n",
        "        return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        # Khi kết hợp với softmax, đạo hàm của loss là (y_pred - y_true)\n",
        "        return y_pred - y_true\n",
        "\n",
        "    def __call__(self, y_pred, y_true):\n",
        "        return self.forward(y_pred, y_true)\n",
        "\n",
        "class SGD:\n",
        "    def __init__(self, model, lr=0.01):\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "\n",
        "    def step(self):\n",
        "        self.model.update(self.lr)\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.model.zero_grad()"
      ],
      "metadata": {
        "id": "d1LTcEaTub8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Softmax:\n",
        "    def forward(self, x):\n",
        "        x = x - np.max(x, axis=1, keepdims=True)\n",
        "        exp = np.exp(x)\n",
        "        self.output = exp / np.sum(exp, axis=1, keepdims=True)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        return y_pred - y_true\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "hbLlU0-8ub5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential:\n",
        "    def __init__(self, layers):\n",
        "        self.layers = layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        for layer in self.layers[::-1]:\n",
        "            grad_output = layer.backward(grad_output)\n",
        "        return grad_output\n",
        "\n",
        "    def update(self, lr):\n",
        "        for layer in self.layers:\n",
        "            layer.update(lr)\n",
        "\n",
        "    def zero_grad(self):\n",
        "        for layer in self.layers:\n",
        "            layer.zero_grad()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        for layer in self.layers:\n",
        "            layer.eval()\n",
        "\n",
        "    def train(self):\n",
        "        for layer in self.layers:\n",
        "            layer.train()\n",
        "\n",
        "class Flatten:\n",
        "    def forward(self, x):\n",
        "        self.input_shape = x.shape\n",
        "        return x.reshape(x.shape[0], -1)\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        return grad_output.reshape(self.input_shape)\n",
        "\n",
        "    def update(self, lr):\n",
        "        pass\n",
        "\n",
        "    def zero_grad(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def eval(self):\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "xTg7yL7nub3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock:\n",
        "    \"\"\"\n",
        "    Khối Residual gồm 2 lớp Conv2d với ReLU và thêm skip connection.\n",
        "    Nếu số kênh của input và output không khớp, thực hiện phép chiếu (projection).\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, padding_type='edge'):\n",
        "        self.conv1 = Conv2d(in_channels, out_channels, kernel_size, stride, padding, padding_type)\n",
        "        self.relu1 = ReLU()\n",
        "        self.conv2 = Conv2d(out_channels, out_channels, kernel_size, 1, padding, padding_type)\n",
        "        self.relu2 = ReLU()\n",
        "        # Nếu số kênh không khớp hoặc stride khác 1, dùng projection\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.proj = Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, padding_type=padding_type)\n",
        "        else:\n",
        "            self.proj = None\n",
        "        # Lưu lại các giá trị cần dùng cho backward\n",
        "        self.add = None\n",
        "        self.input = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.input = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        if self.proj is not None:\n",
        "            identity = self.proj(x)\n",
        "        else:\n",
        "            identity = x\n",
        "        self.add = out + identity\n",
        "        out = self.relu2(self.add)\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # Backward qua ReLU cuối cùng\n",
        "        grad_relu2 = grad_output * (self.add > 0)\n",
        "        # Tách gradient cho 2 nhánh: qua conv2 và qua skip connection\n",
        "        grad_conv2 = grad_relu2.copy()\n",
        "        grad_identity = grad_relu2.copy()\n",
        "        grad_conv2 = self.conv2.backward(grad_conv2)\n",
        "        grad_conv2 = self.relu1.backward(grad_conv2)\n",
        "        grad_conv2 = self.conv1.backward(grad_conv2)\n",
        "        if self.proj is not None:\n",
        "            grad_identity = self.proj.backward(grad_identity)\n",
        "        grad_input = grad_conv2 + grad_identity\n",
        "        return grad_input\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.conv1.update(lr)\n",
        "        self.conv2.update(lr)\n",
        "        if self.proj is not None:\n",
        "            self.proj.update(lr)\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.conv1.zero_grad()\n",
        "        self.conv2.zero_grad()\n",
        "        if self.proj is not None:\n",
        "            self.proj.zero_grad()\n",
        "\n",
        "    def eval(self):\n",
        "        self.conv1.eval()\n",
        "        self.conv2.eval()\n",
        "        if self.proj is not None:\n",
        "            self.proj.eval()\n",
        "\n",
        "    def train(self):\n",
        "        self.conv1.train()\n",
        "        self.conv2.train()\n",
        "        if self.proj is not None:\n",
        "            self.proj.train()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n"
      ],
      "metadata": {
        "id": "xymS8pgSub0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTModel:\n",
        "    def __init__(self, in_channels, nums_classes, size, cfg=None):\n",
        "        self.conv_layer, out_size = self._make_conv_layer(in_channels, size, cfg)\n",
        "        self.fc_layer = self._make_fc_layer(out_size, nums_classes)\n",
        "        self.softmax = Softmax()\n",
        "\n",
        "    def _make_conv_layer(self, in_channels, size, cfg=None):\n",
        "        # Nếu không có cấu hình, chỉ trả về đầu vào ban đầu\n",
        "        if cfg is None:\n",
        "            return None, (in_channels, size[0], size[1])\n",
        "        scale = 1\n",
        "        conv_layer = []\n",
        "        for layer in cfg:\n",
        "            if isinstance(layer, (list, tuple)):\n",
        "                # Cấu hình dạng [out_channels, kernel_size, stride, padding]\n",
        "                conv_layer.append(Conv2d(in_channels, layer[0], layer[1], layer[2], layer[3]))\n",
        "                in_channels = layer[0]\n",
        "            elif isinstance(layer, str):\n",
        "                if layer == 'M':\n",
        "                    conv_layer.append(MaxPool2d(2, 2))\n",
        "                    scale *= 2\n",
        "                # Sử dụng 'Res' để đánh dấu ResidualBlock (skip connection)\n",
        "                elif layer in ['R', 'Res']:\n",
        "                    conv_layer.append(ResidualBlock(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\n",
        "        return Sequential(conv_layer), (in_channels, size[0] // scale, size[1] // scale)\n",
        "\n",
        "    def _make_fc_layer(self, out_size, nums_classes):\n",
        "        return Sequential([\n",
        "            Flatten(),\n",
        "            Linear(out_size[0] * out_size[1] * out_size[2], nums_classes),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.conv_layer is not None:\n",
        "            x = self.conv_layer(x)\n",
        "        x = self.fc_layer(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        grad_output = y_pred - y_true\n",
        "        grad_output = self.fc_layer.backward(grad_output)\n",
        "        if self.conv_layer is not None:\n",
        "            grad_output = self.conv_layer.backward(grad_output)\n",
        "        return grad_output\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "    def update(self, lr):\n",
        "        if self.conv_layer is not None:\n",
        "            self.conv_layer.update(lr)\n",
        "        self.fc_layer.update(lr)\n",
        "\n",
        "    def zero_grad(self):\n",
        "        if self.conv_layer is not None:\n",
        "            self.conv_layer.zero_grad()\n",
        "        self.fc_layer.zero_grad()\n",
        "\n",
        "    def eval(self):\n",
        "        if self.conv_layer is not None:\n",
        "            self.conv_layer.eval()\n",
        "        self.fc_layer.eval()\n",
        "\n",
        "    def train(self):\n",
        "        if self.conv_layer is not None:\n",
        "            self.conv_layer.train()\n",
        "        self.fc_layer.train()"
      ],
      "metadata": {
        "id": "45TgYcQTubyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataset:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.reshape(-1, 1, 28, 28)\n",
        "        self.y = self._convert_to_one_hot(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def _convert_to_one_hot(self, y):\n",
        "        one_hot = np.zeros((len(y), 10))\n",
        "        one_hot[np.arange(len(y)), y.astype(int)] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class Dataloader:\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.n_batches = len(dataset) // batch_size\n",
        "        if len(dataset) % batch_size != 0:\n",
        "            self.n_batches += 1\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(self.n_batches):\n",
        "            batch_X = self.dataset.X[i*self.batch_size : (i+1)*self.batch_size]\n",
        "            batch_y = self.dataset.y[i*self.batch_size : (i+1)*self.batch_size]\n",
        "            yield batch_X, batch_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n"
      ],
      "metadata": {
        "id": "PnweKfATubwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data, mnist.target\n",
        "X = X.to_numpy().astype(np.float32) / 255.0\n",
        "y = y.to_numpy()\n",
        "\n",
        "# Chia dữ liệu thành train/validation/test (tương đương 64%/16%/20% của toàn bộ dữ liệu)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = MNISTDataset(X_train, y_train)\n",
        "val_dataset = MNISTDataset(X_val, y_val)\n",
        "test_dataset = MNISTDataset(X_test, y_test)\n",
        "\n",
        "# Cấu hình mạng với skip connection: ban đầu Conv2d, sau đó ResidualBlock, rồi MaxPool2d\n",
        "cfg = [\n",
        "    [4, 3, 1, 1],\n",
        "    'ReLU',    # ResidualBlock với skip connection\n",
        "    'M',\n",
        "]\n",
        "\n",
        "# Khởi tạo dataloader cho train và validation\n",
        "train_dataloader = Dataloader(train_dataset, 64)\n",
        "val_dataloader = Dataloader(val_dataset, 64)\n",
        "\n",
        "model = MNISTModel(1, 10, (28, 28), cfg)\n",
        "loss_fn = CrossEntropyLoss()\n",
        "optimizer = SGD(model, 0.00001)\n",
        "\n",
        "EPOCHS = 5\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Huấn luyện trên tập train\n",
        "    if hasattr(model, 'train'):\n",
        "        model.train()  # Nếu model có phương thức train() thì chuyển sang chế độ training\n",
        "    epoch_train_losses = []\n",
        "    for batch_X, batch_y in train_dataloader:\n",
        "        y_pred = model(batch_X)\n",
        "        loss = loss_fn(y_pred, batch_y)\n",
        "        model.backward(y_pred, batch_y)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        epoch_train_losses.append(loss)\n",
        "    avg_train_loss = sum(epoch_train_losses) / len(epoch_train_losses)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Đánh giá trên tập validation\n",
        "    if hasattr(model, 'eval'):\n",
        "        model.eval()   # Chuyển model sang chế độ eval để không ảnh hưởng bởi dropout, batchnorm,...\n",
        "    epoch_val_losses = []\n",
        "    for batch_X, batch_y in val_dataloader:\n",
        "        y_pred_val = model(batch_X)\n",
        "        loss_val = loss_fn(y_pred_val, batch_y)\n",
        "        epoch_val_losses.append(loss_val)\n",
        "    avg_val_loss = sum(epoch_val_losses) / len(epoch_val_losses)\n",
        "    val_losses.append(avg_val_loss)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "# Vẽ đồ thị loss của cả tập train và validation\n",
        "plt.plot(range(1, EPOCHS+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, EPOCHS+1), val_losses, label='Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Đánh giá trên tập test\n",
        "if hasattr(model, 'eval'):\n",
        "    model.eval()\n",
        "y_pred = model(X_test.reshape(-1, 1, 28, 28))\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.array(y_test).astype(int)\n",
        "print(\"Test Accuracy:\", np.mean(y_pred == y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "jixDA0nyubtX",
        "outputId": "93d9fba4-b28b-430e-f735-f814ee7b2f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.6727 | Val Loss: 0.3585\n",
            "Epoch 2/5 | Train Loss: 0.3059 | Val Loss: 0.2898\n",
            "Epoch 3/5 | Train Loss: 0.2551 | Val Loss: 0.2521\n",
            "Epoch 4/5 | Train Loss: 0.2255 | Val Loss: 0.2279\n",
            "Epoch 5/5 | Train Loss: 0.2058 | Val Loss: 0.2116\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAY45JREFUeJzt3Xd4VGXexvHvTHpPIB1CQu9NmoFVUFBULFhWZFHK2kVXlnV39bUAumtvqwioqyCuBXUVXQsIKKh06V1qCKQRQiqpM+f9Y5KBgSQkIclkJvfnuuYyOXPK78wB5+Y5z3Mek2EYBiIiIiJuwuzsAkRERETqk8KNiIiIuBWFGxEREXErCjciIiLiVhRuRERExK0o3IiIiIhbUbgRERERt6JwIyIiIm5F4UZERETcisKNSBM3ceJEEhISnF1GnQwbNoxhw4Y1+nEr+8xMJhPTp08/57bTp0/HZDLVaz3Lly/HZDKxfPnyet2viFRO4UakjkwmU41e+kKr2saNGzGZTDz22GNVrrN3715MJhNTp05txMrqZtasWcybN8/ZZTgYNmwYPXr0cHYZIo3K09kFiLiq999/3+H3+fPns2TJkrOWd+3a9byO8/bbb2O1Ws9rH03VBRdcQJcuXfjoo4/4xz/+Uek6H374IQC33nrreR2rsLAQT8+G/V/erFmzCA8PZ+LEiQ7LL774YgoLC/H29m7Q44uIjcKNSB2d+WW7Zs0alixZcs4v4ZMnT+Lv71/j43h5edWpPlcxbtw4Hn/8cdasWcOFF1541vsfffQRXbp04YILLjiv4/j6+p7X9ufDbDY79fgizY1uS4k0oIpbAhs2bODiiy/G39+f//u//wPgyy+/ZNSoUcTGxuLj40P79u156qmnsFgsDvs4s//IoUOHMJlMvPjii7z11lu0b98eHx8fBgwYwPr1689ZU1ZWFg899BA9e/YkMDCQ4OBgrrzySrZs2eKwXkU/kU8++YR//vOftG7dGl9fX4YPH86+ffvO2m9FLX5+fgwcOJCff/65Rp/RuHHjgFMtNKfbsGEDe/bssa9T08+sMpX1ufnll18YMGAAvr6+tG/fnjfffLPSbefOncull15KZGQkPj4+dOvWjdmzZzusk5CQwI4dO1ixYoX9lmRFf6Oq+tx8+umn9OvXDz8/P8LDw7n11ls5evSowzoTJ04kMDCQo0ePMnr0aAIDA4mIiOChhx6q0XnX1KxZs+jevTs+Pj7ExsYyefJksrOzHdbZu3cvN954I9HR0fj6+tK6dWtuueUWcnJy7OssWbKE3/3ud4SGhhIYGEjnzp3tf+ZFGotabkQa2PHjx7nyyiu55ZZbuPXWW4mKigJg3rx5BAYGMnXqVAIDA/nhhx944oknyM3N5YUXXjjnfj/88EPy8vK4++67MZlMPP/889xwww0cOHCg2taeAwcOsHDhQn7/+9/Ttm1b0tPTefPNNxk6dCg7d+4kNjbWYf1nn30Ws9nMQw89RE5ODs8//zzjxo1j7dq19nXeeecd7r77bgYPHsyUKVM4cOAA1157LS1atCAuLq7a82jbti2DBw/mk08+4ZVXXsHDw8PhHAH+8Ic/1Mtndrpt27Zx+eWXExERwfTp0ykrK2PatGn263O62bNn0717d6699lo8PT353//+x3333YfVamXy5MkAvPrqqzzwwAMEBgby6KOPAlS6rwrz5s1j0qRJDBgwgGeeeYb09HT+9a9/sXLlSjZt2kRoaKh9XYvFwsiRIxk0aBAvvvgiS5cu5aWXXqJ9+/bce++9tTrvykyfPp0ZM2YwYsQI7r33Xvbs2cPs2bNZv349K1euxMvLi5KSEkaOHElxcTEPPPAA0dHRHD16lK+//prs7GxCQkLYsWMHV199Nb169eLJJ5/Ex8eHffv2sXLlyvOuUaRWDBGpF5MnTzbO/Cs1dOhQAzDmzJlz1vonT548a9ndd99t+Pv7G0VFRfZlEyZMMOLj4+2/Hzx40ACMli1bGllZWfblX375pQEY//vf/6qts6ioyLBYLA7LDh48aPj4+BhPPvmkfdmPP/5oAEbXrl2N4uJi+/J//etfBmBs27bNMAzDKCkpMSIjI40+ffo4rPfWW28ZgDF06NBq6zEMw3jjjTcMwFi8eLF9mcViMVq1amUkJibal9X1MzMMwwCMadOm2X8fPXq04evrayQlJdmX7dy50/Dw8DjrOlZ23JEjRxrt2rVzWNa9e/dKz7fis/zxxx8Nwzj1mfXo0cMoLCy0r/f1118bgPHEE084nAvgcG0MwzD69u1r9OvX76xjnWno0KFG9+7dq3w/IyPD8Pb2Ni6//HKHPxczZ840AOPdd981DMMwNm3aZADGp59+WuW+XnnlFQMwjh07ds66RBqSbkuJNDAfHx8mTZp01nI/Pz/7z3l5eWRmZnLRRRdx8uRJdu/efc79jhkzhrCwMPvvF110EWBrmTlXPWaz7a++xWLh+PHj9tsHGzduPGv9SZMmOXSEPfM4v/76KxkZGdxzzz0O602cOJGQkJBznkfFuXh5eTncmlqxYgVHjx6135KC8//MKlgsFhYvXszo0aNp06aNfXnXrl0ZOXLkWeufftycnBwyMzMZOnQoBw4ccLglU1MVn9l9993n0Bdn1KhRdOnShW+++easbe655x6H3y+66KJzXuuaWLp0KSUlJUyZMsX+5wLgzjvvJDg42F5LxbVcvHgxJ0+erHRfFa1NX375pdt2ghfXoHAj0sBatWpV6SiZHTt2cP311xMSEkJwcDARERH2zsg1+cI8/UsZsAedEydOVLud1WrllVdeoWPHjvj4+BAeHk5ERARbt26t9LjnOk5SUhIAHTt2dFjPy8uLdu3anfM8AFq2bMnIkSP54osvKCoqAmy3pDw9Pbn55pvt653vZ1bh2LFjFBYWnlUzQOfOnc9atnLlSkaMGEFAQAChoaFERETY+5HUJdxUfGaVHatLly729yv4+voSERHhsCwsLOyc1/p8avH29qZdu3b299u2bcvUqVP597//TXh4OCNHjuSNN95wOP8xY8YwZMgQ7rjjDqKiorjlllv45JNPFHSk0SnciDSw0//VXyE7O5uhQ4eyZcsWnnzySf73v/+xZMkSnnvuOYAafRmc3jfldIZhVLvd008/zdSpU7n44ov5z3/+w+LFi1myZAndu3ev9Lh1PU5t3XrrreTm5vL1119TUlLCf//7X3ufGKifz6wu9u/fz/Dhw8nMzOTll1/mm2++YcmSJfz5z39u0OOerqpr0Nheeukltm7dyv/93/9RWFjIn/70J7p3786RI0cA25/1n376iaVLl3LbbbexdetWxowZw2WXXVavnZ9FzkUdikWcYPny5Rw/fpzPP/+ciy++2L784MGDDX7szz77jEsuuYR33nnHYXl2djbh4eG13l98fDxgG0lz6aWX2peXlpZy8OBBevfuXaP9XHvttQQFBfHhhx/i5eXFiRMnHG5J1ednFhERgZ+fH3v37j3rvT179jj8/r///Y/i4mK++uorh1asH3/88axta/pk44rPbM+ePQ6fWcWyivcbw+m1nN7SVlJSwsGDBxkxYoTD+j179qRnz5489thjrFq1iiFDhjBnzhz7c4rMZjPDhw9n+PDhvPzyyzz99NM8+uij/Pjjj2ftS6ShqOVGxAkq/iV+eutHSUkJs2bNapRjn9nq8umnn541BLmm+vfvT0REBHPmzKGkpMS+fN68eWcNJa6On58f119/Pd9++y2zZ88mICCA6667zqFuqJ/PzMPDg5EjR7Jw4UIOHz5sX75r1y4WL1581rpnHjcnJ4e5c+eetd+AgIAanXP//v2JjIxkzpw5FBcX25d/99137Nq1i1GjRtX2lOpsxIgReHt789prrzmc4zvvvENOTo69ltzcXMrKyhy27dmzJ2az2X4OWVlZZ+2/T58+AA7nKdLQ1HIj4gSDBw8mLCyMCRMm8Kc//QmTycT7779f77d6KnP11Vfz5JNPMmnSJAYPHsy2bdv44IMPatw/5kxeXl784x//4O677+bSSy9lzJgxHDx4kLlz59Z6n7feeivz589n8eLFjBs3joCAAPt79f2ZzZgxg0WLFnHRRRdx3333UVZWxuuvv0737t3ZunWrfb3LL78cb29vrrnmGu6++27y8/N5++23iYyMJDU11WGf/fr1Y/bs2fzjH/+gQ4cOREZGntUyA7bP7LnnnmPSpEkMHTqUsWPH2oeCJyQk2G951Zdjx45V+gTotm3bMm7cOB555BFmzJjBFVdcwbXXXsuePXuYNWsWAwYMsPdp+uGHH7j//vv5/e9/T6dOnSgrK+P999/Hw8ODG2+8EYAnn3ySn376iVGjRhEfH09GRgazZs2idevW/O53v6vXcxKpltPGaYm4maqGglc1DHflypXGhRdeaPj5+RmxsbHG3/72N2Px4sUOQ4YNo+qh4C+88MJZ++SM4c6VKSoqMv7yl78YMTExhp+fnzFkyBBj9erVxtChQx2GMVcMXz5z6G/F8efOneuwfNasWUbbtm0NHx8fo3///sZPP/101j7PpayszIiJiTEA49tvvz3r/bp+ZoZR+WezYsUKo1+/foa3t7fRrl07Y86cOca0adPOuo5fffWV0atXL8PX19dISEgwnnvuOePdd981AOPgwYP29dLS0oxRo0YZQUFBDsPgzxwKXmHBggVG3759DR8fH6NFixbGuHHjjCNHjjisM2HCBCMgIOCsz6KyOitT8TiCyl7Dhw+3rzdz5kyjS5cuhpeXlxEVFWXce++9xokTJ+zvHzhwwPjjH/9otG/f3vD19TVatGhhXHLJJcbSpUvt6yxbtsy47rrrjNjYWMPb29uIjY01xo4da/z222/nrFOkPpkMoxH+qSgiIiLSSNTnRkRERNyKwo2IiIi4FYUbERERcSsKNyIiIuJWFG5ERETErSjciIiIiFtpdg/xs1qtpKSkEBQUVONHpYuIiIhzGYZBXl4esbGxDjPYV6bZhZuUlBTi4uKcXYaIiIjUQXJyMq1bt652nWYXboKCggDbhxMcHOzkakRERKQmcnNziYuLs3+PV6fZhZuKW1HBwcEKNyIiIi6mJl1K1KFYRERE3IrCjYiIiLgVhRsRERFxK82uz42IiJw/i8VCaWmps8sQN+Pt7X3OYd41oXAjIiI1ZhgGaWlpZGdnO7sUcUNms5m2bdvi7e19XvtRuBERkRqrCDaRkZH4+/vrYahSbyoespuamkqbNm3O68+Wwo2IiNSIxWKxB5uWLVs6uxxxQxEREaSkpFBWVoaXl1ed96MOxSIiUiMVfWz8/f2dXIm4q4rbURaL5bz2o3AjIiK1oltR0lDq68+Wwo2IiIi4FYUbERGRWkpISODVV191dhlSBYUbERFxWyaTqdrX9OnT67Tf9evXc9ddd51XbcOGDWPKlCnntQ+pnEZL1aOM3CKOF5TQNUYTcoqINAWpqan2nxcsWMATTzzBnj177MsCAwPtPxuGgcViwdPz3F+NERER9Vuo1Cu13NSTRdtTGfzsDzz6xTZnlyIiIuWio6Ptr5CQEEwmk/333bt3ExQUxHfffUe/fv3w8fHhl19+Yf/+/Vx33XVERUURGBjIgAEDWLp0qcN+z7wtZTKZ+Pe//83111+Pv78/HTt25Kuvvjqv2v/73//SvXt3fHx8SEhI4KWXXnJ4f9asWXTs2BFfX1+ioqK46aab7O999tln9OzZEz8/P1q2bMmIESMoKCg4r3pciVpu6skF8WGYTLDxcDZbj2TTq3Wos0sSEWlQhmFQWHp+Q3brys/Lo95G1jz88MO8+OKLtGvXjrCwMJKTk7nqqqv45z//iY+PD/Pnz+eaa65hz549tGnTpsr9zJgxg+eff54XXniB119/nXHjxpGUlESLFi1qXdOGDRu4+eabmT59OmPGjGHVqlXcd999tGzZkokTJ/Lrr7/ypz/9iffff5/BgweTlZXFzz//DNhaq8aOHcvzzz/P9ddfT15eHj///DOGYdT5M3I1Cjf1JDLIl1E9Y1i4OYV5qw7x8s19nF2SiEiDKiy10O2JxU459s4nR+LvXT9fYU8++SSXXXaZ/fcWLVrQu3dv++9PPfUUX3zxBV999RX3339/lfuZOHEiY8eOBeDpp5/mtddeY926dVxxxRW1runll19m+PDhPP744wB06tSJnTt38sILLzBx4kQOHz5MQEAAV199NUFBQcTHx9O3b1/AFm7Kysq44YYbiI+PB6Bnz561rsGV6bZUPZo4pC0AX29JJTO/2MnViIhITfTv39/h9/z8fB566CG6du1KaGgogYGB7Nq1i8OHD1e7n169etl/DggIIDg4mIyMjDrVtGvXLoYMGeKwbMiQIezduxeLxcJll11GfHw87dq147bbbuODDz7g5MmTAPTu3Zvhw4fTs2dPfv/73/P2229z4sSJOtXhqtRyU4/6xIXSOy6ULcnZfLT2MA8M7+jskkREGoyflwc7nxzptGPXl4CAAIffH3roIZYsWcKLL75Ihw4d8PPz46abbqKkpKTa/Zw5XYDJZMJqtdZbnacLCgpi48aNLF++nO+//54nnniC6dOns379ekJDQ1myZAmrVq3i+++/5/XXX+fRRx9l7dq1tG3btkHqaWrUclPPJg62NQH+Z20SpZaG+UMtItIUmEwm/L09nfJqyKckr1y5kokTJ3L99dfTs2dPoqOjOXToUIMdrzJdu3Zl5cqVZ9XVqVMnPDxswc7T05MRI0bw/PPPs3XrVg4dOsQPP/wA2K7NkCFDmDFjBps2bcLb25svvviiUc/BmdRyU8+u6hnDP7/ZTXpuMYt3pHF1r1hnlyQiIrXQsWNHPv/8c6655hpMJhOPP/54g7XAHDt2jM2bNzssi4mJ4S9/+QsDBgzgqaeeYsyYMaxevZqZM2cya9YsAL7++msOHDjAxRdfTFhYGN9++y1Wq5XOnTuzdu1ali1bxuWXX05kZCRr167l2LFjdO3atUHOoSlSy0098/H04A+DbL3p56085NxiRESk1l5++WXCwsIYPHgw11xzDSNHjuSCCy5okGN9+OGH9O3b1+H19ttvc8EFF/DJJ5/w8ccf06NHD5544gmefPJJJk6cCEBoaCiff/45l156KV27dmXOnDl89NFHdO/eneDgYH766SeuuuoqOnXqxGOPPcZLL73ElVde2SDn0BSZjOY0NgzIzc0lJCSEnJwcgoMb5mF76blFDHn2B8qsBl8/8Dt6tAppkOOIiDSmoqIiDh48SNu2bfH19XV2OeKGqvszVpvvb7XcNICoYF+u6hkDwHurDjm3GBERkWZG4aaBTBicAMCXW1I4rmHhIiIijUbhpoFc0CaUnq1CKCmz8vH6ZGeXIyIi0mwo3DQQk8nExPLWm/+sSaJMw8JFREQahcJNA7q6dwwtA7xJzSni+53pzi5HRESkWVC4aUA+nh6MHVg+LFwdi0VERBqFwk0Du/XCeDzMJtYdzGJnSq6zyxEREXF7CjcNLDrElyt6RAMaFi4iItIYFG4aQUXH4oWbj3KioPqJ10REROT8KNw0gv7xYXSPDaa4zMqCXzUsXETE1QwbNowpU6bYf09ISODVV1+tdhuTycTChQvP+9j1tZ/mROGmEZhMJvtD/d5frWHhIiKN5ZprruGKK66o9L2ff/4Zk8nE1q1ba73f9evXc9ddd51veQ6mT59Onz59zlqempra4PNCzZs3j9DQ0AY9RmNSuGkk1/aOJczfi6PZhSzdleHsckREmoXbb7+dJUuWcOTIkbPemzt3Lv3796dXr1613m9ERAT+/v71UeI5RUdH4+Pj0yjHchcKN43E1+vUsHB1LBYRaRxXX301ERERzJs3z2F5fn4+n376KbfffjvHjx9n7NixtGrVCn9/f3r27MlHH31U7X7PvC21d+9eLr74Ynx9fenWrRtLliw5a5u///3vdOrUCX9/f9q1a8fjjz9OaWkpYGs5mTFjBlu2bMFkMmEymew1n3lbatu2bVx66aX4+fnRsmVL7rrrLvLz8+3vT5w4kdGjR/Piiy8SExNDy5YtmTx5sv1YdXH48GGuu+46AgMDCQ4O5uabbyY9/dTz27Zs2cIll1xCUFAQwcHB9OvXj19//RWApKQkrrnmGsLCwggICKB79+58++23da6lJjwbdO/i4NYL43nzpwOsPnCc3Wm5dIlumFnJRUQahWFA6UnnHNvLH0ymc67m6enJ+PHjmTdvHo8++iim8m0+/fRTLBYLY8eOJT8/n379+vH3v/+d4OBgvvnmG2677Tbat2/PwIEDz3kMq9XKDTfcQFRUFGvXriUnJ8ehf06FoKAg5s2bR2xsLNu2bePOO+8kKCiIv/3tb4wZM4bt27ezaNEili5dCkBISMhZ+ygoKGDkyJEkJiayfv16MjIyuOOOO7j//vsdAtyPP/5ITEwMP/74I/v27WPMmDH06dOHO++885znU9n5VQSbFStWUFZWxuTJkxkzZgzLly8HYNy4cfTt25fZs2fj4eHB5s2b8fLyAmDy5MmUlJTw008/ERAQwM6dOwkMDKx1HbWhcNOIYkP9uLxbFN9tT+O9VUk8c0NPZ5ckIlJ3pSfh6VjnHPv/UsA7oEar/vGPf+SFF15gxYoVDBs2DLDdkrrxxhsJCQkhJCSEhx56yL7+Aw88wOLFi/nkk09qFG6WLl3K7t27Wbx4MbGxts/j6aefPqufzGOPPWb/OSEhgYceeoiPP/6Yv/3tb/j5+REYGIinpyfR0dFVHuvDDz+kqKiI+fPnExBgO/+ZM2dyzTXX8NxzzxEVFQVAWFgYM2fOxMPDgy5dujBq1CiWLVtWp3CzbNkytm3bxsGDB4mLiwNg/vz5dO/enfXr1zNgwAAOHz7MX//6V7p06QJAx44d7dsfPnyYG2+8kZ49bd957dq1q3UNtaXbUo2sYlj4F5uOkHOy7k2EIiJSM126dGHw4MG8++67AOzbt4+ff/6Z22+/HQCLxcJTTz1Fz549adGiBYGBgSxevJjDhw/XaP+7du0iLi7OHmwAEhMTz1pvwYIFDBkyhOjoaAIDA3nsscdqfIzTj9W7d297sAEYMmQIVquVPXv22Jd1794dDw8P++8xMTFkZNStv2fF+VUEG4Bu3boRGhrKrl27AJg6dSp33HEHI0aM4Nlnn2X//v32df/0pz/xj3/8gyFDhjBt2rQ6deCuLbXcNLKBbVvQJTqI3Wl5LPj1MHdd3N7ZJYmI1I2Xv60FxVnHroXbb7+dBx54gDfeeIO5c+fSvn17hg4dCsALL7zAv/71L1599VV69uxJQEAAU6ZMoaSk/p5Ltnr1asaNG8eMGTMYOXIkISEhfPzxx7z00kv1dozTVdwSqmAymbBaG26k7vTp0/nDH/7AN998w3fffce0adP4+OOPuf7667njjjsYOXIk33zzDd9//z3PPPMML730Eg888ECD1aOWm0Z2+mzh81cnYbEazi1IRKSuTCbbrSFnvGrQ3+Z0N998M2azmQ8//JD58+fzxz/+0d7/ZuXKlVx33XXceuut9O7dm3bt2vHbb7/VeN9du3YlOTmZ1NRU+7I1a9Y4rLNq1Sri4+N59NFH6d+/Px07diQpKclhHW9vbywWyzmPtWXLFgoKCuzLVq5cidlspnPnzjWuuTYqzi85+dRz2nbu3El2djbdunWzL+vUqRN//vOf+f7777nhhhuYO3eu/b24uDjuuecePv/8c/7yl7/w9ttvN0itFRRunOC6Pq0I9ffiyIlCftitYeEiIg0tMDCQMWPG8Mgjj5CamsrEiRPt73Xs2JElS5awatUqdu3axd133+0wEuhcRowYQadOnZgwYQJbtmzh559/5tFHH3VYp2PHjhw+fJiPP/6Y/fv389prr/HFF184rJOQkMDBgwfZvHkzmZmZFBcXn3WscePG4evry4QJE9i+fTs//vgjDzzwALfddpu9v01dWSwWNm/e7PDatWsXI0aMoGfPnowbN46NGzeybt06xo8fz9ChQ+nfvz+FhYXcf//9LF++nKSkJFauXMn69evp2rUrAFOmTGHx4sUcPHiQjRs38uOPP9rfaygKN07g5+3BmAG2e5fzVh10cjUiIs3D7bffzokTJxg5cqRD/5jHHnuMCy64gJEjRzJs2DCio6MZPXp0jfdrNpv54osvKCwsZODAgdxxxx3885//dFjn2muv5c9//jP3338/ffr0YdWqVTz++OMO69x4441cccUVXHLJJURERFQ6HN3f35/FixeTlZXFgAEDuOmmmxg+fDgzZ86s3YdRifz8fPr27evwuuaaazCZTHz55ZeEhYVx8cUXM2LECNq1a8eCBQsA8PDw4Pjx44wfP55OnTpx8803c+WVVzJjxgzAFpomT55M165dueKKK+jUqROzZs0673qrYzIMo1ndF8nNzSUkJIScnByCg503FPvIiZNc/PyPWA1Y8ueL6RgV5LRaRERqoqioiIMHD9K2bVt8fX2dXY64oer+jNXm+1stN07SOsyfy7rZmhDfW33IucWIiIi4EYUbJ6qYb+q/G46SU6hh4SIiIvVB4caJEtu1pHNUEIWlFj7VbOEiIiL1QuHGiU6fLVzDwkVEROqHwo2Tje4bS7CvJ4ezTrJ8j4aFi0jT18zGoUgjqq8/Wwo3Tubv7XnasPBDzi1GRKQaFU+9PXnSSZNlitureCr06VNH1IWmX2gCxicm8O9fDvLz3kz2ZeTTIbJhZ0sVEakLDw8PQkND7XMU+fv725/yK3K+rFYrx44dw9/fH0/P84snCjdNQFwLf4Z3iWLprnTmrz7Ek9f1cHZJIiKVqpixuq6TMIpUx2w206ZNm/MOzQo3TcTEwQks3ZXOfzcc4a8jOxPk63XujUREGpnJZCImJobIyEhKS/UIC6lf3t7emM3n32NG4aaJGNKhJR0iA9mXkc9nG44waUhbZ5ckIlIlDw+P8+4XIdJQ1KG4iTh9WPh7qw5h1bBwERGROlG4aUJu6NuKIF9PDh0/yYq9x5xdjoiIiEtSuGlCAnw8ubm/bVj4exoWLiIiUicKN03M+MR4TCZYvucYB47lO7scERERl6Nw08TEtwzgks6RgG1KBhEREakdhZsmaGJ5x+LPNhwhv7jMucWIiIi4GIWbJuh3HcJpFxFAfnEZ/91wxNnliIiIuBSFmybIbDYxITEBgPdWa1i4iIhIbSjcNFE39mtNoI8nB44V8Mu+TGeXIyIi4jKcHm7eeOMNEhIS8PX1ZdCgQaxbt67a9bOzs5k8eTIxMTH4+PjQqVMnvv3220aqtvEE+nhyU7/WgGYLFxERqQ2nhpsFCxYwdepUpk2bxsaNG+nduzcjR46sckK2kpISLrvsMg4dOsRnn33Gnj17ePvtt2nVqlUjV944xifGA/DjngySjhc4uRoRERHX4NRw8/LLL3PnnXcyadIkunXrxpw5c/D39+fdd9+tdP13332XrKwsFi5cyJAhQ0hISGDo0KH07t27kStvHO0iAhnWOQLD0LBwERGRmnJauCkpKWHDhg2MGDHiVDFmMyNGjGD16tWVbvPVV1+RmJjI5MmTiYqKokePHjz99NNYLJYqj1NcXExubq7Dy5VUzDf1yfpkCjQsXERE5JycFm4yMzOxWCxERUU5LI+KiiItLa3SbQ4cOMBnn32GxWLh22+/5fHHH+ell17iH//4R5XHeeaZZwgJCbG/4uLi6vU8GtrQjhG0DQ8gr7iMzzcddXY5IiIiTZ7TOxTXhtVqJTIykrfeeot+/foxZswYHn30UebMmVPlNo888gg5OTn2V3JyciNWfP7MZpO97838VYcwDA0LFxERqY7Twk14eDgeHh6kp6c7LE9PTyc6OrrSbWJiYujUqRMeHh72ZV27diUtLY2SkpJKt/Hx8SE4ONjh5Wpu6teaAG8P9mbks2r/cWeXIyIi0qQ5Ldx4e3vTr18/li1bZl9mtVpZtmwZiYmJlW4zZMgQ9u3bh9VqtS/77bffiImJwdvbu8FrdpYgXy9uLB8WPnflIecWIyIi0sQ59bbU1KlTefvtt3nvvffYtWsX9957LwUFBUyaNAmA8ePH88gjj9jXv/fee8nKyuLBBx/kt99+45tvvuHpp59m8uTJzjqFRjO+/InFy3ank5x10rnFiIiINGGezjz4mDFjOHbsGE888QRpaWn06dOHRYsW2TsZHz58GLP5VP6Ki4tj8eLF/PnPf6ZXr160atWKBx98kL///e/OOoVG0yEykIs6hvPz3kzeX5PE/13V1dkliYiINEkmo5n1UM3NzSUkJIScnByX63+zbFc6t7/3K8G+nqz5v+H4ezs1m4qIiDSa2nx/u9Roqebuks6RxLf0J7eojIWbUpxdjoiISJOkcONCzGYTt11oGxb+noaFi4iIVErhxsX8vn8cfl4e7EnPY/UBDQsXERE5k8KNiwnx8+LGfraJQt/TbOEiIiJnUbhxQRPKh4Uv2ZnOkRMaFi4iInI6hRsX1DEqiCEdWmI14P01mi1cRETkdAo3Lmri4LYALFifTFFp1bOii4iINDcKNy7q0i6RtA7zI/tkKV9u1mzhIiIiFRRuXJTHabOFz12pYeEiIiIVFG5c2Jj+bfDz8mB3Wh7rDmY5uxwREZEmQeHGhYX4ezG6b/mw8NWHnFuMiIhIE6Fw4+ImDLbdmlq8I52U7EInVyMiIuJ8Cjcurkt0MIntWmKxGvxHw8JFREQUbtzBhMEJAHy07rCGhYuISLOncOMGRnSNpFWoHydOlvLVFs0WLiIizZvCjRvw9DBzW6JmCxcREQGFG7cxpn8cPp5mdqTksiHphLPLERERcRqFGzcRFuDN6D62YeFzNVu4iIg0Ywo3bqSiY/Gi7Wmk5RQ5txgREREnUbhxI91igxnYtgUWq8EHazUsXEREmieFGzczsbz15sO1GhYuIiLNk8KNm7m8WxQxIb4cLyjhm62pzi5HRESk0SncuBlPDzO3XmgbFj5Pw8JFRKQZUrhxQ2MHtsHb08y2ozlsPJzt7HJEREQalcKNG2oR4M11vWMB20P9REREmhOFGzdVMSz8222ppOdqWLiIiDQfCjduqkerEPrHh1FmNfhg7WFnlyMiItJoFG7c2MQhCYBtWHhJmdW5xYiIiDQShRs3NrJ7NNHBvmTmF/PtNg0LFxGR5kHhxo15eZgZN6gNoPmmRESk+VC4cXNjB7XB28PMluRsNidnO7scERGRBqdw4+bCA324uncMoGHhIiLSPCjcNAMV8019vTWFjDwNCxcREfemcNMM9GodygVtQim1GHy0NtnZ5YiIiDQohZtmouKhfh+sTdKwcBERcWsKN83ElT1iiAjyISOvmO+2a1i4iIi4L4WbZsLb08ytg2yzhatjsYiIuDOFm2Zk7KA4vDxMbDyczdYj2c4uR0REpEEo3DQjkUG+jOppGxY+T603IiLiphRumpmJQ9oC8PWWVDLzi51cjYiISP1TuGlm+sSF0jsulBKLlY/XabZwERFxPwo3zdDEwbaOxe+vSaLUomHhIiLiXhRumqGresYQHuhDem4xi3ekObscERGReqVw0wz5eHrwh/LZwjUsXERE3I3CTTM1blAbPM0m1h86wfajOc4uR0REpN4o3DRTUcG+XNVTs4WLiIj7Ubhpxirmm/pySwpZBSXOLUZERKSeKNw0Yxe0CaVnqxBKyqx8pGHhIiLiJhRumjGTycTEitnC1yRRpmHhIiLiBhRumrmre8fQMsCblJwiluxMd3Y5IiIi503hppnz8fRg7EDbsPC56lgsIiJuQOFGuPXCeDzMJtYdzGJXaq6zyxERETkvCjdCdIgvV/SIBjQsXEREXJ/CjQDYOxZ/sekoJzQsXEREXJjCjQDQPz6M7rHBFJdZWfBrsrPLERERqTOFGwFsw8IrHur3/moNCxcREdelcCN21/aOJczfi6PZhSzdleHsckREROpE4UbsfL1ODQtXx2IREXFVCjfioGJY+OoDx9mTlufsckRERGpN4UYcxIb6cXm3KADmqfVGRERckMKNnKViWPjCTUfJOVnq3GJERERqqUmEmzfeeIOEhAR8fX0ZNGgQ69atq3LdefPmYTKZHF6+vr6NWK37G9i2BV2igygstfCJhoWLiIiLcXq4WbBgAVOnTmXatGls3LiR3r17M3LkSDIyqh6tExwcTGpqqv2VlJTUiBW7v9NnC39v9SEsVsO5BYmIiNSC08PNyy+/zJ133smkSZPo1q0bc+bMwd/fn3fffbfKbUwmE9HR0fZXVFRUI1bcPFzXpxWh/l4cOVHID7s1LFxERFyHU8NNSUkJGzZsYMSIEfZlZrOZESNGsHr16iq3y8/PJz4+nri4OK677jp27NhR5brFxcXk5uY6vOTc/Lw9GDMgDtCwcBERcS1ODTeZmZlYLJazWl6ioqJIS0urdJvOnTvz7rvv8uWXX/Kf//wHq9XK4MGDOXLkSKXrP/PMM4SEhNhfcXFx9X4e7uq2C+Mxm+CXfZnsTdewcBERcQ1Ovy1VW4mJiYwfP54+ffowdOhQPv/8cyIiInjzzTcrXf+RRx4hJyfH/kpOVgfZmmod5s9l5cPC31t9yLnFiIiI1JBTw014eDgeHh6kp6c7LE9PTyc6OrpG+/Dy8qJv377s27ev0vd9fHwIDg52eEnNVcw39fnGo+QUali4iIg0fU4NN97e3vTr149ly5bZl1mtVpYtW0ZiYmKN9mGxWNi2bRsxMTENVWazltiuJZ2jgjhZYuFTDQsXEREX4PTbUlOnTuXtt9/mvffeY9euXdx7770UFBQwadIkAMaPH88jjzxiX//JJ5/k+++/58CBA2zcuJFbb72VpKQk7rjjDmedgltzmC18TRJWDQsXEZEmztPZBYwZM4Zjx47xxBNPkJaWRp8+fVi0aJG9k/Hhw4cxm09lsBMnTnDnnXeSlpZGWFgY/fr1Y9WqVXTr1s1Zp+D2RveN5dnvdpF0/CTLf8vg0i4aei8iIk2XyTCMZvVP8dzcXEJCQsjJyVH/m1r45zc7efvng1zUMZz3bx/k7HJERKSZqc33t9NvS4lrGJ+YgMkEP+/NZP+xfGeXIyIiUiWFG6mRuBb+DC+/HTVfD/UTEZEmTOFGaqxivqnPNhwhr0jDwkVEpGlSuJEaG9KhJR0iAykosfDZhsqfCC0iIuJsCjdSY6cPC5+/WsPCRUSkaVK4kVq5oW8rgnw9OZhZwIq9x5xdjoiIyFkUbqRWAnw8ubm/ZgsXEZGmS+FGam18YjwmEyzfc4yDmQXOLkdERMSBwo3UWnzLAC7pHAmo9UZERJoehRupk9OHhecXlzm3GBERkdMo3Eid/K5DOO0iAsgvLuPzjRoWLiIiTYfCjdSJ2WxiQmICAPNWHdKwcBERaTIUbqTObuzXmkAfTw4cK+CXfZnOLkdERARQuJHzEOjjyU39WgPqWCwiIk2Hwo2cl/GJ8QD8sCeDpOMaFi4iIs6ncCPnpV1EIMM6R2AYtikZREREnE3hRs5bxXxTn/yaTIGGhYuIiJMp3Mh5G9oxgrbhAeQVlfH5pqPOLkdERJo5hRs5b2azyd73Zv6qQxiGhoWLiIjzKNxIvbipX2sCvD3Ym5HPqv3HnV2OiIg0Ywo3Ui+CfL24sXxY+NyVh5xbjIiINGsKN1Jvxpc/sXjZ7nSSs046txgREWm2FG6k3nSIDOSijuEYBry/RsPCRUTEORRupF5VzBb+8brDnCzRsHAREWl8CjdSry7pHEl8S39yi8pYuCnF2eWIiEgzVKdwk5yczJEjR+y/r1u3jilTpvDWW2/VW2HimsxmE7ddaBsW/p6GhYuIiBPUKdz84Q9/4McffwQgLS2Nyy67jHXr1vHoo4/y5JNP1muB4np+3z8OPy8P9qTnsfqAhoWLiEjjqlO42b59OwMHDgTgk08+oUePHqxatYoPPviAefPm1Wd94oJC/Ly4sV8rQLOFi4hI46tTuCktLcXHxweApUuXcu211wLQpUsXUlNT6686cVkTyoeFL9mZzpETGhYuIiKNp07hpnv37syZM4eff/6ZJUuWcMUVVwCQkpJCy5Yt67VAcU0do4IY0qElVg0LFxGRRlancPPcc8/x5ptvMmzYMMaOHUvv3r0B+Oqrr+y3q0QmDm4LwIL1yRSVWpxcjYiINBeeddlo2LBhZGZmkpubS1hYmH35XXfdhb+/f70VJ67t0i6RtA7z48iJQr7cfJQxA9o4uyQREWkG6tRyU1hYSHFxsT3YJCUl8eqrr7Jnzx4iIyPrtUBxXR6nzRY+d6WGhYuISOOoU7i57rrrmD9/PgDZ2dkMGjSIl156idGjRzN79ux6LVBc25j+bfDz8mB3Wh7rDmY5uxwREWkG6hRuNm7cyEUXXQTAZ599RlRUFElJScyfP5/XXnutXgsU1xbi78XovuXDwlcfcm4xIiLSLNQp3Jw8eZKgoCAAvv/+e2644QbMZjMXXnghSUkaGSOOJgy23ZpavCOdlOxCJ1cjIiLurk7hpkOHDixcuJDk5GQWL17M5ZdfDkBGRgbBwcH1WqC4vi7RwSS2a4nFavAfDQsXEZEGVqdw88QTT/DQQw+RkJDAwIEDSUxMBGytOH379q3XAsU9TCifLfyjdYc1LFxERBpUncLNTTfdxOHDh/n1119ZvHixffnw4cN55ZVX6q04cR8jukbSKtSPEydL+WqLZgsXEZGGU6dwAxAdHU3fvn1JSUmxzxA+cOBAunTpUm/Fifvw9DBzW6JmCxcRkYZXp3BjtVp58sknCQkJIT4+nvj4eEJDQ3nqqaewWq31XaO4iTH94/DxNLMjJZcNSSecXY6IiLipOoWbRx99lJkzZ/Lss8+yadMmNm3axNNPP83rr7/O448/Xt81ipsIC/BmdB/bsPC5mi1cREQaiMmow/2B2NhY5syZY58NvMKXX37Jfffdx9GjR+utwPqWm5tLSEgIOTk5GtnlBDtTcrnqtZ/xMJtY+fdLiQ7xdXZJIiLiAmrz/V2nlpusrKxK+9Z06dKFrCw9hVaq1i02mIFtW2CxGnywVsPCRUSk/tUp3PTu3ZuZM2eetXzmzJn06tXrvIsS9zaxfFj4h2s1LFxEROpfnWYFf/755xk1ahRLly61P+Nm9erVJCcn8+2339ZrgeJ+Lu8WRUyIL6k5RXyzNZUb+7V2dkkiIuJG6tRyM3ToUH777Teuv/56srOzyc7O5oYbbmDHjh28//779V2juBlPDzO3XmgbFj5Pw8JFRKSe1alDcVW2bNnCBRdcgMXSdG81qENx05BVUMKFzyyjpMzKf+8dTL/4MGeXJCIiTViDdygWOV8tAry5tncsYHuon4iISH1RuBGnqehY/O22VNJzi5xbjIiIuA2FG3GaHq1C6B8fRpnV4IO1h51djoiIuIlajZa64YYbqn0/Ozv7fGqRZmjC4AR+TTrBh2sPc/8lHfD2VN4WEZHzU6twExIScs73x48ff14FSfNyRY9oooJ9SM8t5tttqYzu28rZJYmIiIurVbiZO3duQ9UhzZSXh5lbB8Xz0pLfmLvqkMKNiIicN90DEKcbO6gN3h5mtiRnszk529nliIiIi1O4EacLD/Th6t4xgIaFi4jI+VO4kSahYlj411tTyMjTsHAREak7hRtpEnq1DqVvm1BKLQYfrU12djkiIuLCFG6kyahovflgbRIlZVbnFiMiIi5L4UaajCt7xBAR5ENGXjHfbU91djkiIuKiFG6kyfD2NDNuUBtAHYtFRKTumkS4eeONN0hISMDX15dBgwaxbt26Gm338ccfYzKZGD16dMMWKI3mD4Pa4OVhYuPhbLYeyXZ2OSIi4oKcHm4WLFjA1KlTmTZtGhs3bqR3796MHDmSjIyMarc7dOgQDz30EBdddFEjVSqNITLIl1E9bcPC56n1RkRE6sDp4ebll1/mzjvvZNKkSXTr1o05c+bg7+/Pu+++W+U2FouFcePGMWPGDNq1a9eI1UpjmFAxLHxLKpn5xc4tRkREXI5Tw01JSQkbNmxgxIgR9mVms5kRI0awevXqKrd78skniYyM5Pbbbz/nMYqLi8nNzXV4SdPWt00YveNCKbFY+XidZgsXEZHacWq4yczMxGKxEBUV5bA8KiqKtLS0Srf55ZdfeOedd3j77bdrdIxnnnmGkJAQ+ysuLu6865aGN3FwPADvr0mi1KJh4SIiUnNOvy1VG3l5edx22228/fbbhIeH12ibRx55hJycHPsrOVkPiHMFV/WMITzQm/TcYhbvqDzoioiIVKZWs4LXt/DwcDw8PEhPT3dYnp6eTnR09Fnr79+/n0OHDnHNNdfYl1mttn/Ve3p6smfPHtq3b++wjY+PDz4+Pg1QvTQkH08P/jAonteW7eW9VYe4uless0sSEREX4dSWG29vb/r168eyZcvsy6xWK8uWLSMxMfGs9bt06cK2bdvYvHmz/XXttddyySWXsHnzZt1ycjPjBrXB02xi/aETbD+a4+xyRETERTi15QZg6tSpTJgwgf79+zNw4EBeffVVCgoKmDRpEgDjx4+nVatWPPPMM/j6+tKjRw+H7UNDQwHOWi6uLyrYlyt7xvC/LSm8t+oQL/y+t7NLEhERF+D0cDNmzBiOHTvGE088QVpaGn369GHRokX2TsaHDx/GbHaprkFSjyYOTuB/W1L4cksKj1zVlRYB3s4uSUREmjiTYRiGs4toTLm5uYSEhJCTk0NwcLCzy5FzMAyDa2euZNvRHP46sjOTL+ng7JJERMQJavP9rSYRadJMJpP9oX4frEmiTMPCRUTkHBRupMm7ulcMLQO8SckpYsnO9HNvICIizZrCjTR5vl4ejB1omy18ruabEhGRc1C4EZcw7sI2eJhNrDuYxa5UTaEhIiJVU7gRlxAT4scVPWwPdnxPrTciIlINhRtxGRPLOxZ/sekoJwpKnFuMiIg0WQo34jL6x4fRLSaY4jIrC37VHGEiIlI5hRtxGSaTiYlDEgB4f7WGhYuISOUUbsSlXNs7ljB/L45mF7J0V4azyxERkSZI4UZciq+XB7eUDwtXx2IREamMwo24nFsvjMfDbGL1gePsSctzdjkiItLEKNyIy2kV6sfl3WwTq85T642IiJxB4UZcUsV8Uws3HSXnZKlzixERkSZF4UZc0qC2LegSHURhqYVPNCxcREROo3AjLslkMtkf6vfe6kNYrIZzCxIRkSZD4UZc1nV9WhHi58WRE4X8sFvDwkVExEbhRlyWn7cHtwyMAzQsXERETlG4EZd224XxmE3wy75M9qZrWLiIiCjciItrHebPiK62YeHvrT7k3GJERKRJULgRl1cx39TnG4+SU6hh4SIizZ3Cjbi8xHYt6RwVxMkSC59qWLiISLOncFOfju0BQ0OSG5vJZGL84HgA3l+ThFXDwkVEmjWFm/qSmwKzB8ObF8HmD6Gs2NkVNSvX921FsK8nScdPsvw3DQsXEWnOFG7qS8omMHtB2jZYeC+80h2WPwv5x5xdWbPg7+3JmAG2YeFzVx5ybjEiIuJUCjf1pcsomLoTRkyHoFgoOAbLn4FXusHCybbQIw3qtgsTMJng572Z7D+W7+xyRETESRRu6pN/C/jdn2HKVrjxHWjVDywlsPk/MOd3MO9q2PMdWK3OrtQttWnpz/AutmHh8/VQPxGRZkvhpiF4eEHPm+DOH+D2pdD9BjB5wKGf4aNbYGY/WPsmFOuhc/WtYr6pzzYcIa9Iw8JFRJojhZuGFjcAfj8XHtwCQx4E3xDIOgDf/Q1e7g6LH4UTSc6u0m0M6dCSDpGBFJRY+GzDEWeXIyIiTqBw01hC4+CyJ2HqLhj1ErTsAMU5sHomvNYHFtwGSas1lPw8mUwmJpS33sxfrWHhIiLNkcJNY/MOgAF3wOT18IdPod0lYFhh11cw9wp4+xLY+gmUlTi7Upd1Q99WBPl6cjCzgBV7NVpNRKS5UbhxFrMZOl0O4xfCvavhgvHg4WMbUv75nfCvXvDTi1Bw3NmVupwAH09+30+zhYuINFcKN01BVDe49nXbUPJLH4PAaMhLhR+esg0l/+pPkLHL2VW6lPGJ8ZhMsHzPMQ5mFji7HBERaUQKN01JQDhc/FeYsg2ufwtiekNZEWx8D2ZdCPNHw94lGkpeAwnhAVzSORJQ642ISHOjcNMUeXpD7zFw1wqYtAi6XgsmMxz4ET64Cd4YCOv/DSVqkajOhNOGhecXlzm3GBERaTQKN02ZyQTxiTDmffjTJki8H3yC4fhe+OYv8HI3WDINcjTkuTIXdQinXUQA+cVlfL5Rn5GISHOhcOMqwhJg5D9t/XKueA7C2kJRNqx8FV7tBZ9OgiO/OrnIpsVsNjEhMQGAeasOaVi4iEgzoXDjanyC4MJ74IENcMtHkHARGBbY8Tn8ezj8ewRs/y9Y9HRegBv7tSbQx5MDxwr4ZV+ms8sREZFGoHDjqswe0OUqmPg13P0z9BkHHt5wZD189kf4V2/45RU4meXsSp0q0MeTm/q1BtSxWESkuVC4cQcxvWD0LPjzDhj2CAREQO5RWDodXukOX0+FzL3OrtJpxifGA/DDngySjqsTtoiIu1O4cSeBkTDsYVvIuW4WRPWA0pPw6zswsz988HvY/0Ozm+KhXUQgQztFYBi2KRlERMS9Kdy4I08f6DsO7vkFJnwNna8CTLD3e3j/epiVCBvmQWmhsyttNBOHJADwya/JFGhYuIiIW1O4cWcmE7S9CMZ+ZOuAPOge8A6EY7vgfw/ahpIvewpyU51daYMb2jGCtuEB5BWV8fmmo84uR0REGpDCTXPRsj1c+ZxtKPnl/4SQNlCYBT+/CK/2gP/eaZvXyk2ZzSZuu9DW92b+qkMYzezWnIhIc6Jw09z4hsDg+20PBbz5fWiTCNYy2PYJvDUM3r0Cdn4JVouzK613N/VvTYC3B3sz8lm1XxOSioi4K4Wb5srDE7pdC39cBHf+CL3GgNkTDq+GT8bDa31g1UwoynF2pfUm2NeLG8uHhc9deci5xYiISINRuBFodQHc8BZM2Q4XPQR+LSD7MHz/qK1fzrd/g+P7nV1lvRhf/sTiZbvTSc466dxiRESkQSjcyCnBMTD8cVu/nGteg4iuUJIP696E1/vBR2Ph4E8uPZS8Q2QgF3UMxzDg/TUaFi4i4o4UbuRsXn7QbwLctxpuWwgdLwcM2PMtvHcNzLkINn0ApUXOrrROJpbPFv7xusOcLNGwcBERd6NwI1UzmaD9JTDuU7j/VxhwB3j5Q/o2+PI+2yirH5+B/AxnV1orwzpH0qaFP7lFZSzclOLsckREpJ4p3EjNhHeEUS/Znn48YgYEt4KCY7DiWdsUDwvvg9Stzq6yRjzMJvuUDO9pWLiIiNtRuJHa8W8Bv5sCD26Bm+ZC6wFgKYHNH8CbF8G8q2H3N01+KPnv+8fh5+XBnvQ8Vh/QsHAREXeicCN14+EFPW6AO5bC7Uuhx41g8oBDP8PHf7B1QF4zB4rznF1ppUL8vLjhglaAZgsXEXE3Cjdy/uIGwE3vwpStMGQK+IbCiYOw6O+2oeSL/g9OHHJykWer6Fi8ZGc6R05oWLiIiLtQuJH6E9IaLpthG0o+6mVo2RGKc2HNG/BaX1hwKyStajJDyTtGBTGkQ0usGhYuIuJWFG6k/nkHwIDbYfI6GPcZtL8UDCvs+h/MvdI2zcOWBVBW4uxKmVD+UL8F65MpKm3a/YRERKRmFG6k4ZjN0PEyuO0LuG8N9JsInr6Quhm+uMs2lHzFC1CQ6bQSh3eNonWYH9knS/lys2YLFxFxBwo30jgiu8I1/4I/74RLH4fAaMhPhx//YRtK/tUDkL6z0cs6fVj43JUaFi4i4g4UbqRxBbSEix+CKdvghn9DbF8oK4KN82F2Isy/Dn77HqzWRivp5v5x+HqZ2Z2Wx7qDWY12XBERaRgKN+Icnt7Q6/e2Gcn/uBi6XQcmMxxYDh/+Ht4YAOvehpKCBi8l1N+b6/vaZgt/b/WhBj+eiIg0LIUbcS6TCdpcCDfPhz9thsT7wScYju+Dbx+Cl7vCkicgO7lBy5gw2HZravGOdFKyCxv0WCIi0rBMRjPrZJCbm0tISAg5OTkEBwc7uxypTHEebP4I1s6GrAO2ZSYP6HYtXHgfxA1skMPe8tZq1hzIIjzQh5Hdo7iyRwyD2rXAy0P/BhARcbbafH83if9rv/HGGyQkJODr68ugQYNYt25dlet+/vnn9O/fn9DQUAICAujTpw/vv/9+I1YrDc4nCAbdBfdvgLEfQ9uLwbDAji/gncvg7eGw7TOwlNbrYR++sith/l5k5hfzwdrD3PrOWgb8cyl//XQLP+xOp7hMQ8VFRFyB01tuFixYwPjx45kzZw6DBg3i1Vdf5dNPP2XPnj1ERkaetf7y5cs5ceIEXbp0wdvbm6+//pq//OUvfPPNN4wcOfKcx1PLjYtK225rydn6KViKbcuCW8HAO+GCCbY5r+pBSZmVVfszWbQ9je93ppNVcOpZPEE+nlzaNZIre0QztFMkft4e9XJMERE5t9p8fzs93AwaNIgBAwYwc+ZMAKxWK3FxcTzwwAM8/PDDNdrHBRdcwKhRo3jqqafOua7CjYvLPwa/vgvr/w0FGbZlnn7QZywMuhciOtXbocosVtYdymLR9jQWbU8jI6/Y/p6flwfDOkdwRY9oLu0SSZCvV70dV0REzuYy4aakpAR/f38+++wzRo8ebV8+YcIEsrOz+fLLL6vd3jAMfvjhB6699loWLlzIZZdddtY6xcXFFBef+lLKzc0lLi5O4cbVlRXD9v/CmlmQtu3U8g4jbP1y2l9q66xcT6xWg03JJ/huWxrfbU/j6Gmdjr09zFzUMZwrekRzWbcoQv296+24IiJiU5tw49lINVUqMzMTi8VCVFSUw/KoqCh2795d5XY5OTm0atWK4uJiPDw8mDVrVqXBBuCZZ55hxowZ9Vq3NAGePtDnD9B7LCSthDWzYfc3sG+p7RXRBQbdA73GgLf/eR/ObDbRL74F/eJb8Oiormw/mst321NZtD2NA5kFLNudwbLdGXiaTSS2b8kVPaK5vFs0EUE+9XCyIiJSG05tuUlJSaFVq1asWrWKxMRE+/K//e1vrFixgrVr11a6ndVq5cCBA+Tn57Ns2TKeeuopFi5cyLBhw85aVy03zUjWAVj7Fmx6H0rybcv8WkD/STDgDgiOrfdDGobBb+n59qCzOy3P/p7ZBP0TWnBlj2iu6BFNTIhfvR9fRKS5aDa3pSrccccdJCcns3jx4nOuqz43zUBRDmz6ANbOgezy2b7NntD9etstq1YXNNihD2YW2IPO1iM5Du/1iQvlyh7RXNkjhjYtz781SUSkOXGZcAO2DsUDBw7k9ddfB2ytMm3atOH++++vcYfiP/7xjxw4cIDly5efc12Fm2bEaoE939puWSWtPLU87kK48F7ocjV4NNyd2SMnTto7I284fILT/6Z1iwm2BZ2e0XSIDGqwGkRE3IVLhZsFCxYwYcIE3nzzTQYOHMirr77KJ598wu7du4mKimL8+PG0atWKZ555BrD1oenfvz/t27enuLiYb7/9locffpjZs2dzxx13nPN4CjfNVMomWDPH1gnZWv58nJA2tufp9L0N/EIb9PAZuUUs3mHrjLz2YBYW66m/dh0iA+23rrrFBGOqx47QIiLuwqXCDcDMmTN54YUXSEtLo0+fPrz22msMGjQIgGHDhpGQkMC8efMAeOyxx1iwYAFHjhzBz8+PLl268OCDDzJmzJgaHUvhppnLS4P178Cv78DJ47ZlXgHQd5ytA3LL9g1eQlZBCUt22oLOyn2ZlFpO/RWMb+nPFd1tQadPXKiCjohIOZcLN41J4UYAKC2EbZ/ablll7CxfaIJOI223q+IHQ4t29TqcvDI5haX8sDud77alseK3YxSXnZoNPTbEl5HlfXT6xYfhYVbQEZHmS+GmGgo34sAw4OAKWD0L9p7RIT0wyhZy4odAm0SI7AbmhpuxpKC4jOV7jvHd9lR+3J1BQcmp6R4035WINHcKN9VQuJEqZe6DLR9C0io4ugEsJY7v+4bYQk78YGgzGGL7gEfDPJm4qNTCz3sz+W57Kkt3ppNbVGZ/L9Tfi8u6RnFlz2iGdAjHx1PTQIiI+1O4qYbCjdRIaZEt4CStgsOr4PBaKC1wXMfLH1oPKG/dGQyt+tfLAwPPVFJmZfWB4yzansr3O9I5rvmuRKQZUriphsKN1ImlDNK22sJO0io4vBoKsxzXMXtBbF+IT7TdyoobVO+jsMosVtYfOsGi7aks2pFGeq7muxKR5kHhphoKN1IvrFbI3HMq7CStgryUM1YyQVSP8rBTfisrKKrS3dWtBINNydks2p7Kd9vTOHJC812JiPtSuKmGwo00CMOwPQ05abXtgYFJqyBr/9nrtWh/6jZW/GAIja+XEVmGYbAjxTbf1Xfb0zhw7NQtNM13JSLuQOGmGgo30mjy0m39dZJW28JO+nbgjL9uQbHlQaf8VlZ45/MekWUYBnsz8stnME91mO/KZIIBmu9KRFyQwk01FG7EaQqzIXltecvOakjZCNYyx3X8WpwakRWfCNG9z3uKiIOZBeXTQKSyRfNdiYiLUriphsKNNBklJ+Hor6f67BxZD6UnHdfxDiwfkTXEFnZa9QOvure2HM0utAedX5M035WIuA6Fm2oo3EiTZSmF1C2nWnYOr7LNcH46D29bwGlTMSJrIPjW7c9xRm4Ri3ems2h7KmsOaL4rEWnaFG6qoXAjLsNqhWO7ylt2ygNPfprjOiYzRPe0jcSq6KQcEF7rQ2UVlLB0ZzrfbU/lF813JSJNkMJNNRRuxGUZBmQdsD1jp+JW1omDZ68X3unU0PP4wRAaV6vD5BaV8sOuDL7dlnrWfFcxIb6M7B7NlT2i6Z/QQvNdiUijUbiphsKNuJXc1PIRWeUv+ySgpwmJKw87FSOyOtZ4+Pm55ru6vHsUV2m+KxFpBAo31VC4Ebd2MgsOrzkVeFI2g2FxXMc//NTQ8zaJttta5nNP21CT+a6u6BHN7zpqvisRqX8KN9VQuJFmpTjfNgqrYsqII+uhrMhxHZ9gW8fkiltZrS4Az+of9FfdfFeBPp4M13xXIlLPFG6qoXAjzVpZsa01J2mlLewcXgPFuY7rePhA6/6nOii3Hgg+gVXu0mI1WHcwS/NdiUiDUriphsKNyGmsFkjfcWr286RVUHDMcR2TB8T0PhV22iSCf4vKd6f5rkSkgSjcVEPhRqQahgHH95+aH+vwKsg+fPZ6EV0dw05Iq0p2pfmuRKT+KNxUQ+FGpJZyjpyaEPTwaji2++x1QuNPPUU5fgi0aOcwIkvzXYnI+VK4qYbCjch5Kjh+2rN2VkLaVjCsjusERJa37JQHnsjuDhOCHsos4DvNdyUitaBwUw2FG5F6VpQLR9admv386AawFDuu4xsCcReeupUV0wc8bX1uNN+ViNSEwk01FG5EGlhpkW3G84opI5LXQkm+4zqefuUjsspbdloPAO8AzXclIlVSuKmGwo1II7OUQfq2U09RPrwaTh53XMfsCbF9Tz1Fuc0gsqwBVc531aaFvz3oaL4rkeZB4aYaCjciTmYYkPnbqZadpFWQe+SMlUwQ1b087AwmL3oAy5LNfLfdNt9VUanmuxJpbhRuqqFwI9IEZR92nP38+N6z12nRDuIHU9xqEKtKu/D5QU9+qGS+qxFdI+nVOpRuscF0iQ7C10tPSBZxBwo31VC4EXEB+RmOs5+nbQPO+F9VUAyWuET2+vbkf9lt+c8BX3KKHEdtmU3QPiKQbrHBdI8NpltMCN1ig2kRoAcIirgahZtqKNyIuKDCbEhed+opykc3grXUYRXDL4zjLS5gm7kLm4qi+TkrlK0FoVg4u+UmJsSXbjHBDqEnroWf+u6INGEKN9VQuBFxA6WFcOTX8tadlZC8HkoLzlrNMHtxMjCeNO849lli2HQygjW5LTlgxJBLgMO6QT6edI0NpltMeeCJDaZjZBDenuaz9isijU/hphoKNyJuyFIKqVttLTtHN9r67GTug7LCKjcp9G5Jimccey3RbDwZwW+WGPYbMRw1IrBiCzReHiY6RgbR7bTQ0zU2mGBNACrS6BRuqqFwI9JMWK2Qe9Q2Mitzb3ng+c0WevJSqtyszORNikcsu8ui2V0WzQFrLPuNWA4YMRRgmxoiroUf3cv773SLCaZ7q2Cig311W0ukASncVEPhRkQozisPPPtOhZ+K3898uvJpjtGC3ywxHDBi7IFnvzWWFFoS6u9T3ocnxN6fp114AJ4euq0lUh8UbqqhcCMiVbJaICf5VNg5vdUnP73KzQoNbw4atttaB4xY9ltj2W/EkOLRijbREbYWnvLQ0zUmCH9vz0Y8KRH3oHBTDYUbEamTwmw4vr888PxWfptrr23ZGSO3TnfUaMkB66mWngNGLCVhHYiMbUu3ViH2lp6IIJ/GOxcRF6RwUw2FGxGpV5YyyE46q1+PkfkbppOZVW5WYPjYw85+ayyZvm3wiOxEWFxXOreOoltsMPEt/DHricsigMJNtRRuRKTRnMw6rV+PLfSUZezBnH0Is1FW6SZWw0QKLdlvjeWwuRWFwe3wiupMWJvutG/bgY566rI0Uwo31VC4ERGns5TCiUP2Pj1lGXsoStuD14m9+JTmVrlZnuHHASOWYz5xlIR2wDuqE+EJPUjo1JNQ/f9M3JzCTTUUbkSkyTIM24zpmXuxHNtDbvJOitP24J29j9DiFMxYK93MYphIM0dy3DeB0rD2+MZ0ISKhBxEJPTAFRoKGqIsbULiphsKNiLiksmKMrANkJ+/i+KFtlKbvwSfnABHFSQRxssrN8k2BZPvHUxbWAf/YrrSI745nZGcIawuemmNLXIfCTTUUbkTErRgGeVkpJO/ZQnbyDsoyfsMvZz9Rpcm05hhmU+X/i7fgQb5/K6wtOxIQ0wXv6C7QsiOEd4KAlo18EiLnpnBTDYUbEWkOSsqs7E/J5PC+beQc2YmR8Rv++QdpYz1Ke1MKgaaiqrf1DoPwDnhFdsYUXh54wjtBWDx4aOoJcQ6Fm2oo3IhIc2UYBkdOFLLjaA5JSfvJO7ITa+ZeIoqSaG9KoZ05ldamqoevG2ZPaNEOU8uOYA895T/7hTXimUhzpHBTDYUbERFHWQUl7ErNZUdKDnuPZJCXsgevE/tohy3wtDel0M6Uir+p6qkp8A93DDvhnaBlBwiNBw89kVnOn8JNNRRuRETOrajUwp60PHaWh55dR7PJSkuileUI7Uwp9sDT3pxCrCmr6h15eEOL9hDeoTzwVLT4dADfkMY7IXF5CjfVULgREakbi9Xg0PECdqbkloeeXHam5HAyP5e2JlsLT/vylp72phTamtPwpaTqHQZGnWrhOb3VJyQOzHpQoThSuKmGwo2ISP3KyCsqDzq59uBzMLMAE1ZamY7bW3ram1Lo6JFGR49UWlirae0xeUBQdPkrxvYKjjnt51jbez7BeoZPM6JwUw2FGxGRhpdfXMbuVFvQ2Zlia+XZk55HSZntQYSBnLTd1jKl0MEjlV6+GXQwpxJZcgQPo+qJSB14BdhCTnBsefCJPhV8gmJtgSgwWs/zcRMKN9VQuBERcY5Si5UDxwrYkZLjcGsrp/BUmDFjJYJsokwniDZn0dE3n3a+ucR5ZBNpyibMkklAyTE8S6qepuIs/uGVtP6c0RLk1wLM5gY4a6kvCjfVULgREWk6DMMgJaeovHUnhx0puRzKLODIiUIKSy1VbudHETHmE3QJOEln/3za+uTSyiObSLIIKcvEvzgDj4J0TJZq+vyczux1WutPjK3lp7KWIO+AejpzqS2Fm2oo3IiINH2GYZBVUELyiUKOnDjJkfL/Jmed+r24rPK5tip4mKFzUCk9ggro5J9PvHcOsR7ZhFuzCCk7hk9hBqa8VCg4VvPCfILPuAVWSUtQYJSGvzcAhZtqKNyIiLg+wzDIzC8h+bTgc+REIclZJzl6opAj2YX2/j1V8TSbiAn1JT7Ei25BhXTwy6ONVw4x5hO0tGbhX5yBOS8V8tIgLxVK8mtYnQkCI88IPrGntQqVv/zC1CG6FhRuqqFwIyLi/qxWg8z84tPCj2PLz9HsQkot1X/9eXmYiA31o3WYH3Fh/rQNstLeN484z2yizdkElRzDnJ8GeSmQWx6C8tPAWlazIj19T93ycrgFFuP4s5dfPXwirk/hphoKNyIiYrUaZORVhJ+THMmyBaCKMJSSXUiZtfqvR28PM63CbOGndZi/7b+hPiT4FRLnmU1YWSam/LTy4FP+qvi5sJqh8GfyDa3kFthp/YCCYiAgwu2fDaRwUw2FGxEROReL1SA9t4jkrDNafsrDT2pOEZZzhB8fz4rw40/c6QEozI+4YDMtrVmY8spbfvLSIDelPASd9nNZ1ROcOjB52Pr6VDcizMWfDaRwUw2FGxEROV9lFitpuUUOHZwrWn6OnigkNaeQc2QffL3M9sATZw8+5b+38CfMzxNTcY5jy8/prT8VPxdkgFF9/yI7F342kMJNNRRuRESkoZVarKTlnN7yc9LhtldabhHn+vb19/awBx7Hlh9/4lr4EeLnhclkAkuZLeBUGoIqWoVSoTin5ifQBJ8NpHBTDYUbERFxtpIyK6k5hWe0/Jy0D31Pz61mBvZygT6e9ttcrStp+Qnx8zrjoAWn3fKq7HZY+S2xOj8b6LTgExoPbQbV4ZOpmsJNNRRuRESkqSsqtZBaTcvPsbxzh58gX89KbnudavkJ8vU6eyPDgJNZp40Aq6Il6FzPBorpDXf/VMezr1xtvr/1lCEREZEmxtfLg7bhAbQNr/yJyEWlFo5mF1bS4bmQoydOkplfQl5RGbtSc9mVWvlUFSF+Xqc6OJ/e8tPCj9ZhXQmM7ll1gWUlkJ9eHnoqaQkK71QfH0OdqeVGRETEzRSWWDiafbLSDs9HThSSVXDuW09h/l4Ot7nOvAXm79247SNquREREWnG/Lw96BAZRIfIoErfLyguO6Plx/G2V/bJUk6cLOXEyRy2Ha28I3LLAO8zWnsqboHZfvb1ct5zdxRuREREmpkAH086RQXRKary8JNXVFoefiqf2yu3qIzjBSUcLyhhy5Gzw0/HyECWTB3a0KdRpSYRbt544w1eeOEF0tLS6N27N6+//joDBw6sdN23336b+fPns337dgD69evH008/XeX6IiIiUjtBvl50ifaiS3Tlt39yCksdbnedOalp6zDnThnh9HCzYMECpk6dypw5cxg0aBCvvvoqI0eOZM+ePURGRp61/vLlyxk7diyDBw/G19eX5557jssvv5wdO3bQqlUrJ5yBiIhI8xLi50WIXwjdY0POes8wjHPO2N7QnN6heNCgQQwYMICZM2cCYLVaiYuL44EHHuDhhx8+5/YWi4WwsDBmzpzJ+PHjz7m+OhSLiIi4ntp8fzfeowUrUVJSwoYNGxgxYoR9mdlsZsSIEaxevbpG+zh58iSlpaW0aNGi0veLi4vJzc11eImIiIj7cmq4yczMxGKxEBUV5bA8KiqKtLS0Gu3j73//O7GxsQ4B6XTPPPMMISEh9ldcXNx51y0iIiJNl1PDzfl69tln+fjjj/niiy/w9fWtdJ1HHnmEnJwc+ys5ObmRqxQREZHG5NQOxeHh4Xh4eJCenu6wPD09nejo6Gq3ffHFF3n22WdZunQpvXr1qnI9Hx8ffHx86qVeERERafqc2nLj7e1Nv379WLZsmX2Z1Wpl2bJlJCYmVrnd888/z1NPPcWiRYvo379/Y5QqIiIiLsLpQ8GnTp3KhAkT6N+/PwMHDuTVV1+loKCASZMmATB+/HhatWrFM888A8Bzzz3HE088wYcffkhCQoK9b05gYCCBgYFOOw8RERFpGpwebsaMGcOxY8d44oknSEtLo0+fPixatMjeyfjw4cOYzacamGbPnk1JSQk33XSTw36mTZvG9OnTG7N0ERERaYKc/pybxqbn3IiIiLgel3nOjYiIiEh9U7gRERERt6JwIyIiIm5F4UZERETcisKNiIiIuBWnDwVvbBWDwzSBpoiIiOuo+N6uySDvZhdu8vLyADSBpoiIiAvKy8sjJCSk2nWa3XNurFYrKSkpBAUFYTKZ6nXfubm5xMXFkZyc7JbP0HH38wP3P0edn+tz93PU+bm+hjpHwzDIy8sjNjbW4eG+lWl2LTdms5nWrVs36DGCg4Pd9g8tuP/5gfufo87P9bn7Oer8XF9DnOO5WmwqqEOxiIiIuBWFGxEREXErCjf1yMfHh2nTpuHj4+PsUhqEu58fuP856vxcn7ufo87P9TWFc2x2HYpFRETEvanlRkRERNyKwo2IiIi4FYUbERERcSsKNyIiIuJWFG5q6KeffuKaa64hNjYWk8nEwoULz7nN8uXLueCCC/Dx8aFDhw7Mmzevwes8H7U9x+XLl2Mymc56paWlNU7BtfTMM88wYMAAgoKCiIyMZPTo0ezZs+ec23366ad06dIFX19fevbsybffftsI1dZeXc5v3rx5Z10/X1/fRqq4dmbPnk2vXr3sDwZLTEzku+++q3YbV7l2FWp7jq50/Srz7LPPYjKZmDJlSrXrudp1rFCT83O1azh9+vSz6u3SpUu12zjj+inc1FBBQQG9e/fmjTfeqNH6Bw8eZNSoUVxyySVs3ryZKVOmcMcdd7B48eIGrrTuanuOFfbs2UNqaqr9FRkZ2UAVnp8VK1YwefJk1qxZw5IlSygtLeXyyy+noKCgym1WrVrF2LFjuf3229m0aROjR49m9OjRbN++vRErr5m6nB/YniJ6+vVLSkpqpIprp3Xr1jz77LNs2LCBX3/9lUsvvZTrrruOHTt2VLq+K127CrU9R3Cd63em9evX8+abb9KrV69q13PF6wg1Pz9wvWvYvXt3h3p/+eWXKtd12vUzpNYA44svvqh2nb/97W9G9+7dHZaNGTPGGDlyZANWVn9qco4//vijARgnTpxolJrqW0ZGhgEYK1asqHKdm2++2Rg1apTDskGDBhl33313Q5d33mpyfnPnzjVCQkIar6h6FhYWZvz73/+u9D1Xvnanq+4cXfX65eXlGR07djSWLFliDB061HjwwQerXNcVr2Ntzs/VruG0adOM3r1713h9Z10/tdw0kNWrVzNixAiHZSNHjmT16tVOqqjh9OnTh5iYGC677DJWrlzp7HJqLCcnB4AWLVpUuY4rX8eanB9Afn4+8fHxxMXFnbOVoKmwWCx8/PHHFBQUkJiYWOk6rnztoGbnCK55/SZPnsyoUaPOuj6VccXrWJvzA9e7hnv37iU2NpZ27doxbtw4Dh8+XOW6zrp+zW7izMaSlpZGVFSUw7KoqChyc3MpLCzEz8/PSZXVn5iYGObMmUP//v0pLi7m3//+N8OGDWPt2rVccMEFzi6vWlarlSlTpjBkyBB69OhR5XpVXcem2q+oQk3Pr3Pnzrz77rv06tWLnJwcXnzxRQYPHsyOHTsafILZuti2bRuJiYkUFRURGBjIF198Qbdu3Spd11WvXW3O0dWuH8DHH3/Mxo0bWb9+fY3Wd7XrWNvzc7VrOGjQIObNm0fnzp1JTU1lxowZXHTRRWzfvp2goKCz1nfW9VO4kTrr3LkznTt3tv8+ePBg9u/fzyuvvML777/vxMrObfLkyWzfvr3ae8WurKbnl5iY6NAqMHjwYLp27cqbb77JU0891dBl1lrnzp3ZvHkzOTk5fPbZZ0yYMIEVK1ZU+eXvimpzjq52/ZKTk3nwwQdZsmRJk+40W1d1OT9Xu4ZXXnml/edevXoxaNAg4uPj+eSTT7j99tudWJkjhZsGEh0dTXp6usOy9PR0goOD3aLVpioDBw5s8oHh/vvv5+uvv+ann34657+MqrqO0dHRDVnieanN+Z3Jy8uLvn37sm/fvgaq7vx4e3vToUMHAPr168f69ev517/+xZtvvnnWuq547aB253impn79NmzYQEZGhkPLrsVi4aeffmLmzJkUFxfj4eHhsI0rXce6nN+Zmvo1PFNoaCidOnWqsl5nXT/1uWkgiYmJLFu2zGHZkiVLqr137g42b95MTEyMs8uolGEY3H///XzxxRf88MMPtG3b9pzbuNJ1rMv5nclisbBt27Ymew3PZLVaKS4urvQ9V7p21anuHM/U1K/f8OHD2bZtG5s3b7a/+vfvz7hx49i8eXOlX/yudB3rcn5naurX8Ez5+fns37+/ynqddv0atLuyG8nLyzM2bdpkbNq0yQCMl19+2di0aZORlJRkGIZhPPzww8Ztt91mX//AgQOGv7+/8de//tXYtWuX8cYbbxgeHh7GokWLnHUK51Tbc3zllVeMhQsXGnv37jW2bdtmPPjgg4bZbDaWLl3qrFOo1r333muEhIQYy5cvN1JTU+2vkydP2te57bbbjIcfftj++8qVKw1PT0/jxRdfNHbt2mVMmzbN8PLyMrZt2+aMU6hWXc5vxowZxuLFi439+/cbGzZsMG655RbD19fX2LFjhzNOoVoPP/ywsWLFCuPgwYPG1q1bjYcfftgwmUzG999/bxiGa1+7CrU9R1e6flU5czSRO1zH053r/FztGv7lL38xli9fbhw8eNBYuXKlMWLECCM8PNzIyMgwDKPpXD+FmxqqGPZ85mvChAmGYRjGhAkTjKFDh561TZ8+fQxvb2+jXbt2xty5cxu97tqo7Tk+99xzRvv27Q1fX1+jRYsWxrBhw4wffvjBOcXXQGXnBjhcl6FDh9rPt8Inn3xidOrUyfD29ja6d+9ufPPNN41beA3V5fymTJlitGnTxvD29jaioqKMq666yti4cWPjF18Df/zjH434+HjD29vbiIiIMIYPH27/0jcM1752FWp7jq50/apy5pe/O1zH053r/FztGo4ZM8aIiYkxvL29jVatWhljxowx9u3bZ3+/qVw/k2EYRsO2DYmIiIg0HvW5EREREbeicCMiIiJuReFGRERE3IrCjYiIiLgVhRsRERFxKwo3IiIi4lYUbkRERMStKNyISLNnMplYuHChs8sQkXqicCMiTjVx4kRMJtNZryuuuMLZpYmIi9Ks4CLidFdccQVz5851WObj4+OkakTE1anlRkSczsfHh+joaIdXWFgYYLtlNHv2bK688kr8/Pxo164dn332mcP227Zt49JLL8XPz4+WLVty1113kZ+f77DOu+++S/fu3fHx8SEmJob777/f4f3MzEyuv/56/P396dixI1999VXDnrSINBiFGxFp8h5//HFuvPFGtmzZwrhx47jlllvYtWsXAAUFBYwcOZKwsDDWr1/Pp59+ytKlSx3Cy+zZs5k8eTJ33XUX27Zt46uvvqJDhw4Ox5gxYwY333wzW7du5aqrrmLcuHFkZWU16nmKSD1p8Kk5RUSqMWHCBMPDw8MICAhweP3zn/80DMM22/k999zjsM2gQYOMe++91zAMw3jrrbeMsLAwIz8/3/7+N998Y5jNZiMtLc0wDMOIjY01Hn300SprAIzHHnvM/nt+fr4BGN999129naeINB71uRERp7vkkkuYPXu2w7IWLVrYf05MTHR4LzExkc2bNwOwa9cuevfuTUBAgP39IUOGYLVa2bNnDyaTiZSUFIYPH15tDb169bL/HBAQQHBwMBkZGXU9JRFxIoUbEXG6gICAs24T1Rc/P78arefl5eXwu8lkwmq1NkRJItLA1OdGRJq8NWvWnPV7165dAejatStbtmyhoKDA/v7KlSsxm8107tyZoKAgEhISWLZsWaPWLCLOo5YbEXG64uJi0tLSHJZ5enoSHh4OwKeffkr//v353e9+xwcffMC6det45513ABg3bhzTpk1jwoQJTJ8+nWPHjvHAAw9w2223ERUVBcD06dO55557iIyM5MorryQvL4+VK1fywAMPNO6JikijULgREadbtGgRMTExDss6d+7M7t27AdtIpo8//pj77ruPmJgYPvroI7p16waAv78/ixcv5sEHH2TAgAH4+/tz44038vLLL9v3NWHCBIqKinjllVd46KGHCA8P56abbmq8ExSRRmUyDMNwdhEiIlUxmUx88cUXjB492tmliIiLUJ8bERERcSsKNyIiIuJW1OdGRJo03TkXkdpSy42IiIi4FYUbERERcSsKNyIiIuJWFG5ERETErSjciIiIiFtRuBERERG3onAjIiIibkXhRkRERNyKwo2IiIi4lf8H0Mf73puPFBsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9423571428571429\n"
          ]
        }
      ]
    }
  ]
}